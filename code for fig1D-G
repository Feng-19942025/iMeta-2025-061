import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix
from scipy.stats import gaussian_kde
import numpy  as np
from sklearn.manifold import TSNE
import matplotlib.pyplot as plt

plt.rcParams.update({
    'font.family': 'serif',
    'font.serif': ['Times New Roman'],
})
plt.rcParams['svg.fonttype'] = 'none'
plt.rcParams.update({'font.size': 12})

class Dataset(Dataset):
    def __init__(self, data, labels):
        self.data = torch.tensor(data.values, dtype=torch.float32)
        self.labels = torch.tensor(labels.values, dtype=torch.long)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return self.data[idx], self.labels[idx]

batch_size = 2
learning_rate = 0.001
num_epochs = 200

data = pd.read_csv('x3.txt', sep='\s+', header=None)
features = data.iloc[:, :-1]
labels = data.iloc[:, -1]

scaler = StandardScaler()
features = scaler.fit_transform(features)

X_train, X_val, y_train, y_val = train_test_split(features, labels, test_size=0.2, random_state=42)

train_dataset = Dataset(pd.DataFrame(X_train), pd.Series(y_train))
val_dataset = Dataset(pd.DataFrame(X_val), pd.Series(y_val))
draw_dataset = Dataset(pd.DataFrame(features), pd.Series(labels))
train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)
val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)
draw_loader = DataLoader(dataset=draw_dataset, batch_size=batch_size, shuffle=False)

num_classes = len(labels.unique())
input_size = features.shape[1]

class NN(nn.Module):
    def __init__(self, input_size, num_classes):
        super(NN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.fc2 = nn.Linear(64, 64)
        self.fc3 = nn.Linear(64, num_classes)

    def forward(self, x):
        x = torch.relu(self.fc1(x))
        x = torch.relu(self.fc2(x))
        x = self.fc3(x)
        return x

model = NN(input_size, num_classes)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=learning_rate)

train_losses = []
val_accuracies = []

for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    for inputs, targets in train_loader:
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, targets)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()

    avg_loss = running_loss / len(train_loader)
    train_losses.append(avg_loss)

    model.eval()
    with torch.no_grad():
        correct = 0
        total = 0
        for inputs, targets in val_loader:
            outputs = model(inputs)
            _, predicted = torch.max(outputs.data, 1)
            total += targets.size(0)
            correct += (predicted == targets).sum().item()

    val_accuracy = 100 * correct / total
    val_accuracies.append(val_accuracy)
    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_loss:.4f}, Accuracy: {val_accuracy:.2f}%')

plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(range(1, num_epochs + 1), train_losses, label='Training Loss')
plt.title('Training Loss vs. Epochs')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.grid()
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(range(1, num_epochs + 1), val_accuracies, label='Validation Accuracy', color='orange')
plt.title('Validation Accuracy vs. Epochs')
plt.xlabel('Epochs')
plt.ylabel('Accuracy (%)')
plt.grid()
plt.legend()

plt.tight_layout()
plt.savefig('LOSS.tif', format='tiff', dpi=300)
plt.savefig('LOSS.svg', format='svg', dpi=300)
plt.show()


plt.figure(figsize=(10, 6))
plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap='viridis', marker='o', alpha=0.5)
plt.title('Scatter Plot of Training Data')
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.grid()
plt.show()

y_true = []
y_pred = []

model.eval()
with torch.no_grad():
    for inputs, targets in draw_loader:
        outputs = model(inputs)
        _, predicted = torch.max(outputs.data, 1)
        y_true.extend(targets.numpy())
        y_pred.extend(predicted.numpy())

conf_matrix = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=range(num_classes), yticklabels=range(num_classes))
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.savefig('CM.tif', format='tiff', dpi=300)
plt.savefig('CM.svg', format='svg', dpi=300)
plt.show()

with torch.no_grad():
    test_logits = []
    test_labels = []
    for inputs, labels in draw_loader:
        outputs = model(inputs)
        test_logits.append(outputs)
        test_labels.append(labels)

# 将 logits 和标签转化为 NumPy 数组
test_logits = torch.cat(test_logits).numpy()
test_labels = torch.cat(test_labels).numpy()

tsne = TSNE(n_components=2, perplexity=4, n_iter=1000, random_state=42)
out = tsne.fit_transform(test_logits)
plt.figure()
x, y = out.T
plt.scatter(x, y, alpha=0.7)
plt.title('Scatter Plot of Test Data')
plt.savefig('SP_NL.tif', format='tiff', dpi=300)
plt.savefig('SP_NL.svg', format='svg', dpi=300)
plt.show()

tsne = TSNE(n_components=2, perplexity=4, n_iter=1000, random_state=42)
out = tsne.fit_transform(test_logits)
plt.figure()
for i in range(num_classes):
    indices = test_labels == i
    x, y = out[indices].T
    plt.scatter(x, y, label=f'G{i + 1}', alpha=1)
plt.legend()
out = tsne.fit_transform(test_logits)
plt.hexbin(out[:, 0], out[:, 1], gridsize=4, cmap='Blues', alpha=0.3)
plt.title('Scatter Plot of Test Data')
plt.savefig('SP_WL.tif', format='tiff', dpi=300)
plt.savefig('SP_WL.svg', format='svg', dpi=300)
plt.show()


